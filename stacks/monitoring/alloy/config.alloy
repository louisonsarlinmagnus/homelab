// //////////////////////////////////////// //
//                  SYSTEM                  //  
// //////////////////////////////////////// //


// ---------------------------- //
//        SYSTEM METRICS        //
// ---------------------------- //


// Defining what metrics we want and excluding a few so as not to overload it
prometheus.exporter.unix "system" {
    disable_collectors  = ["ipvs", "btrfs", "infiniband", "xfs", "zfs"]
    enable_collectors   = ["meminfo"]

    filesystem {
        fs_types_exclude     = "^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|tmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$"
        mount_points_exclude = "^/(dev|proc|run/credentials/.+|sys|var/lib/docker/.+)($|/)"
        mount_timeout        = "5s"
    }

    netclass {
        ignored_devices = "^(veth.*|cali.*|[a-f0-9]{15})$"
    }

    netdev {
        device_exclude = "^(veth.*|cali.*|[a-f0-9]{15})$"
    }
}

// Relabeling the instance and job (usefull in distributed env)
discovery.relabel "system" {
    targets = prometheus.exporter.unix.system.targets

    rule {
        target_label = "instance"
        replacement  = "homelab"
    }

    rule {
        target_label = "job"
        replacement  = "system"
    }
}

// Let scrape what we asked every 10 seconds
prometheus.scrape "system" {
    scrape_interval = "10s"
    targets         = discovery.relabel.system.output
    forward_to      = [prometheus.remote_write.default.receiver]
}

// ---------------------------- //
//         SYSTEM LOGS          //
// ---------------------------- //


// Retrieving last 24h of journalctl and sending it to loki
loki.source.journal "journal" {
    max_age       = "24h0m0s"
    relabel_rules = discovery.relabel.journal.rules
    forward_to    = [loki.write.default.receiver]
    path          = "/var/log/journal"
    labels        = {component = "journalctl"}
}

// Relabeling some entries
discovery.relabel "journal" {
    targets = []

    rule {
        source_labels = ["__journal__systemd_unit"]
        target_label  = "unit"
    }

    rule {
        source_labels = ["__journal__boot_id"]
        target_label  = "boot_id"
    }

    rule {
        source_labels = ["__journal__transport"]
        target_label  = "transport"
    }

    rule {
    source_labels = ["__journal_priority_keyword"]
    target_label  = "level"
    }
}

// Retrieving file in /var/log
local.file_match "system" {
    path_targets    = [{
    __address__     = "localhost",
    __path__        = "/var/log/{syslog,messages,*.log}",
    instance        = "homelab",
    job             = "system",
  }]
}

// Scraping files found above and sending it to loki
loki.source.file "system" {
    targets    = local.file_match.system.targets
    forward_to = [loki.write.default.receiver]
}


// //////////////////////////////////////// //
//                  DOCKER                  //  
// //////////////////////////////////////// //


// ---------------------------- //
//        DOCKER METRICS        //
// ---------------------------- //


// Host Cadvisor on the Docker socket to expose container metrics.

prometheus.exporter.cadvisor "docker_metrics" {
    docker_only     = true
    enabled_metrics = [
        "network",
        "cpu",
        "memory",
        ]
}

discovery.relabel "docker_metrics" {
    targets = prometheus.exporter.cadvisor.docker_metrics.targets

    rule {
        target_label = "job"
        replacement  = "docker"
    }

    rule {
        target_label = "instance"
        replacement  = "homelab"
    }
}

// Configure a prometheus.scrape component to collect cadvisor metrics.
prometheus.scrape "docker_metrics" {
    targets    = discovery.relabel.docker_metrics.output
    forward_to = [ prometheus.remote_write.default.receiver ]

    scrape_interval = "30s"
}


// ---------------------------- //
//         DOCKER LOGS          //
// ---------------------------- //


// Discover Docker containers and extract metadata.
discovery.docker "docker_logs" {
    host = "unix:///var/run/docker.sock"
}

// Define a relabeling rule to create a service name from the container name.
discovery.relabel "docker_logs" {
    targets = []

    rule {
        source_labels   = ["__meta_docker_container_name"]
        regex           = "/(.*)"
        target_label    = "container_name"
    }

    rule {
        target_label = "instance"
        replacement  = "homelab"
    }

    rule {
        source_labels = ["__meta_docker_container_log_stream"]
        target_label  = "stream"
    }
  }

// Configure a loki.source.docker component to collect logs from Docker containers.
loki.source.docker "docker_logs" {
    host            = "unix:///var/run/docker.sock"
    targets         = discovery.docker.docker_logs.targets
    relabel_rules   = discovery.relabel.docker_logs.rules
    forward_to      = [loki.write.default.receiver]
}


// //////////////////////////////////////// //
//             FAIL2BAN GEOIP               //  
// //////////////////////////////////////// //


// Retrieve fail2ban logfile
local.file_match "fail2ban" {
    path_targets        = [{
    __address__         = "localhost",
    __path__            = "/var/log/fail2ban.log",
    // __path_exclude__  = "/var/log/fail2ban.log.*.gz",
    instance            = "homelab",
    job                 = "fail2ban",
  }]
}

// Scrape the file and send it to loki
loki.source.file "fail2ban" {
    targets    = local.file_match.fail2ban.targets
    forward_to = [loki.process.fail2ban_get_ip.receiver]
}

// Process the log entries to extract data
loki.process "fail2ban_get_ip" {
    forward_to = [loki.process.fail2ban_geoip_lookup.receiver]

    // Store in group desired data
    stage.regex {
        expression = "^(?P<time>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2},\\d{3})\\s+(?P<fail2ban_component>fail2ban\\.\\w+)\\s+\\[(?P<pid>\\d+)\\]:\\s+(?P<level>\\w+)\\s+\\[(?P<jail>[^\\]]+)\\]\\s+(?P<action>\\w+)\\s+(?P<ip>(?:\\d{1,3}\\.){3}\\d{1,3})?"
    }

    // Define the time format for the "time" data retrieve in the log entry
    stage.timestamp {
        source = "time"
        format = "2006-01-02 15:04:05,000"
    }

    // Natively associate every regex group with a label with the same name
    stage.labels {
        values = {
            time      = "",
            fail2ban_component = "",
            jail      = "",
            ip        = "",
            action    = "",
        }
    }

}

// Process the log entries to lookup data
loki.process "fail2ban_geoip_lookup" {
    forward_to = [loki.write.default.receiver]

    // Lookup for each ip entry within the GeoLite2 database
    stage.geoip {
        db      = "/usr/share/GeoLite2/GeoLite2-City.mmdb"
        source  = "ip"
        db_type = "city"
    }

    // Natively associate every geoip output with a label with the same name
    stage.labels {
        values = {
            geoip_city_name          = "",
            geoip_country_name       = "",
            // geoip_country_code       = "",
            geoip_continent_name     = "",
            // geoip_continent_code     = "",
            geoip_location_latitude  = "",
            geoip_location_longitude = "",
        }
    }
}


// //////////////////////////////////////// //
//           SMART PLUG METRICS             //  
// //////////////////////////////////////// //

// Scraping Shelly API
prometheus.scrape "shelly_api" {
    targets    = [
        {
            "__scheme__"        = "http",
            "__address__"       = "192.168.1.45",
            "__metrics_path__"  = "/script/1/metrics",
        },
    ]
    forward_to      = [prometheus.remote_write.default.receiver]
    scrape_interval = "10s"
}

// //////////////////////////////////////// //
//          OBSERVABILITY HOARDER           //  
// //////////////////////////////////////// //

// Defining the "default" prometheus instance we want to write to
prometheus.remote_write "default" {
    endpoint {
        url = "http://prometheus:9090/api/v1/write"
    }
}

// Defining the "default" loki instance we want to write to
loki.write "default" {
    endpoint {
        url = "http://loki:3100/loki/api/v1/push"
    }
}

// ALLOY CONFIG

logging {
    level  = "info"
    format = "logfmt"
}

livedebugging {
  enabled = true
}