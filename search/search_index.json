{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to my homelab project","text":"<p>What is a homelab ?</p> <p>A homelab is the name given to a or multiple servers that resides locally in your home and where you host several applications and virtualized systems for testing, developing and for home, personal and functional usage. For example, this project aim to host a bunch of things including a password manager and a recipe book. Most homelab are old gaming computers or Raspberry Pis but some could compete with small to medium company infrastructure. For further investigation, I recommend having a look to r/selfhosted.</p>"},{"location":"#context","title":"Context","text":"<p>As a computer enthusiast and a human living in a SaaS market full of really expensive platforms I want to find a solution that will allow me to make some savings and ensure my privacy on the internet is as intact as possible. As a DevOps engineer I want to practice, learn and develop new skills. Add this to a freshly graduate innocent engineer this lead to my first homelab that has its pros and cons. In this documentation and blog I will write about the research, experimentation and choices in the path of this new project.</p>"},{"location":"#needs","title":"Needs","text":"<p>My need is to be able to host cool free open-source projects and hosting pictures, videos, passwords, recipe, video-game servers, etc. I want something as automated and autonomous as possible, and that I can rely on.</p>"},{"location":"blog/","title":"Index","text":""},{"location":"blog/#blog","title":"Blog","text":"<p>In this section you will find articles write mainly during research sessions.</p>"},{"location":"blog/2025/05/18/environment-setup/","title":"Environment setup","text":"<p>Notes taken during the setup of the system</p>"},{"location":"blog/2025/05/18/environment-setup/#the-system","title":"The System","text":""},{"location":"blog/2025/05/18/environment-setup/#biosuefi","title":"BIOS/UEFI","text":"<p>To begin, once the hardware thrown in the case, we have to tune the BIOS/UEFI to enable some features in the advanced pannel :  </p> <ul> <li>CPU Configuration &gt;  <ul> <li>CPU C States Support =&gt; Enabled</li> <li>Enhanced Halt State (C1E) =&gt; Auto</li> <li>Package C State Support =&gt; Enable</li> <li>C6DRAM =&gt; Enable</li> </ul> </li> <li>Chipset Configuration &gt;<ul> <li>PCI Express Native Control =&gt; Enabled</li> <li>PCH PCIE ASPM Support =&gt; Auto</li> <li>Restore on AC/Power Loss =&gt; Power On</li> </ul> </li> </ul>"},{"location":"blog/2025/05/18/environment-setup/#os","title":"OS","text":"<p>For ease of use and support I will use Ubuntu Server 24.04.2 LTS even if alternative OS like nix are tempting. To get the smallest footprint as possible, I installed the minimal configuration of Ubuntu server without any additional package except OpenSSH for remote access right after the installation.</p>"},{"location":"blog/2025/05/18/environment-setup/#power-savings","title":"Power savings","text":"<p>Once the BIOS configured and the OS installed, let's take a look at the power consumption by installing powertop : <code>sudo apt install powertop</code> .Here we can see that the CPU can't go deeper that C2.</p> <p>The main suspect is the ethernet controller, to set ASPM L1 for this controller : <pre><code>echo 1 | sudo tee /sys/bus/pci/drivers/r8169/0000\\:01\\:00.0/link/l1_aspm\n</code></pre></p> <p>Then we can set the powersave mode for the PCI-e : <pre><code>echo \"powersave\" | sudo tee /sys/module/pcie_aspm/parameters/policy\ncat /sys/module/pcie_aspm/parameters/policy # to confirm\n</code></pre></p> <p>We can also use <code>powertop --auto-tune</code> to tweak other things.</p> <p>And to persist all those commands, let's add them to the reboot cron : <pre><code># To persist those commands\n(sudo crontab -l 2&gt;/dev/null; echo \"@reboot /usr/sbin/powertop --auto-tune\") | sudo crontab -\n(sudo crontab -l 2&gt;/dev/null; echo \"@reboot echo 1 | sudo tee /sys/bus/pci/drivers/r8169/0000\\:01\\:00.0/link/l1_aspm\") | sudo crontab -\n(sudo crontab -l 2&gt;/dev/null; echo \"@reboot echo \"powersave\" | sudo tee /sys/module/pcie_aspm/parameters/policy\") | sudo crontab -\n</code></pre></p> <p>Power consumption</p> <p>At this point the server sips just bellow 12 Watts at idle with HX750i, the N100DC-ITX motherboard, 32 Go of RAM and a 256 Go SATA SSD. Adding 2 12x12 fans add 1.5 Watts for a total bellow 13.5 W.</p>"},{"location":"blog/2025/05/18/environment-setup/#update-07012026-disks-power-savings","title":"UPDATE 07/01/2026 : Disks power savings","text":"<p>During the previous days I worked on hard disks for backups and RAID. Thoses disks increase significantly the overall power consumption.</p> <p>My disks are WD Red Plus, they have been made for servers and therefore better tolerate spinup/spindown.</p> <p>I have 5 disks : 4 WD Red Plus for the RAID5 (sdb, sdd, sde and sdf) and 1 Seagate for backups (sdc).</p> <p>Let's activate the spindown for those 4 disks by adding the following lines to <code>/etc/hdparm.conf</code> : /etc/hdparm.conf<pre><code>command_line {\n  hdparm -S 240 /dev/sdb # 240 * 5s = 20 minutes\n  hdparm -S 240 /dev/sdd\n  hdparm -S 240 /dev/sde\n  hdparm -S 240 /dev/sdf\n}\n</code></pre> To apply, just reboot.</p> <p>We can check that this does exactly what we want :</p> <pre><code>louison@homelab:~/homelab$ date\nWed Jan  7 19:52:27 UTC 2026\nlouison@homelab:~/homelab$ sudo hdparm -C /dev/sdb\n\n/dev/sdb:\n drive state is:  active/idle\n\n# Now lets wait 20 minutes (idle time defined above)\n\nlouison@homelab:~/homelab$ sudo hdparm -C /dev/sdb\n[sudo] password for louison: \n\n/dev/sdb:\n drive state is:  standby\n\n # The disk fall into standby mod (spinoff)\n\nlouison@homelab:~/homelab$ ls /media/raid/jellyfin\nmedia\n\nlouison@homelab:~/homelab$ sudo hdparm -C /dev/sdb\n\n/dev/sdb:\n drive state is:  active/idle\n\n# Accessing our drive (RAID in this case) will spinup the disk\n</code></pre> <p>Power savings</p> <p>Before this improvment, the homelab was drawing between 31 and 33 Watts. When the drive are set on standby mod it goes down to 22 Watts.</p> <p>We still have to work on the backup disk !</p>"},{"location":"blog/2025/05/18/environment-setup/#update-11012025-disabling-disk-spinoff","title":"UPDATE 11/01/2025 : Disabling disk spinoff","text":"<p>HDD spindown could cause damage</p> <p>During the pasts days it appears to me that the disks spinoff is quite not the neat idea I thought for the following reasons :</p> <ul> <li>The RAID5 being \"unreachable\" could cause Jellyfin to crash</li> <li>The disks are being spinup by some process too frequently to be usefull</li> <li>The disks being spindown and up multiple times a day could be harmful to the disks</li> </ul> <p>I have undone the previus update.</p>"},{"location":"blog/2025/05/18/environment-setup/#networking","title":"Networking","text":"<p>Let's change the SSH default port : </p> <ul> <li>Open ssh config <code>sudo nano /etc/ssh/sshd_config</code></li> <li>Edit <code>#Port 22</code> to something else</li> <li>Adding new port to firewall <code>sudo ufw allow xxxx/tcp</code></li> <li>Apply change by restarting SSH <code>sudo systemctl restart ssh.service</code></li> <li>Test the connection <code>ssh &lt;user&gt;@&lt;server_ip&gt; -p xxxx</code></li> <li>Removing port 22 to firewall <code>sudo ufw deny 22/tcp</code></li> </ul> <p>Let's disable password connection for SSH</p> <ul> <li>Open ssh config <code>sudo nano /etc/ssh/sshd_config</code></li> <li>Setting <code>PasswordAuthentication no</code></li> <li>Setting <code>PermitRootLogin prohibit-password</code></li> <li>Apply change by restarting SSH <code>sudo systemctl restart ssh.service</code></li> </ul> <p>Tips</p> <ul> <li><code>sudo ss -tulpn</code> to list all the open ports</li> <li>Don't forget to fix the IP address of the homelab in the router</li> </ul>"},{"location":"blog/2025/05/18/environment-setup/#miscellaneous","title":"Miscellaneous","text":"<p>Don't forget to set the date properly</p> <pre><code>sudo timedatectl set-timezone Europe/Paris\n</code></pre>"},{"location":"blog/2025/05/18/environment-setup/#the-tools","title":"The tools","text":""},{"location":"blog/2025/05/18/environment-setup/#cli-utilities","title":"CLI utilities","text":"<pre><code>sudo apt-get update\nsudo apt install bash-completion\nsudo apt install git\nsudo apt install nano\nsudo apt install cron\nsudo apt install ufw\nsudo apt install pipx &amp;&amp; python3 -m pipx ensurepath &amp;&amp; pipx install mkdocs &amp;&amp; pipx inject mkdocs mkdocs-material\n</code></pre>"},{"location":"blog/2025/05/18/environment-setup/#docker","title":"Docker","text":"<p>The first tool to install and Setup is Docker.  </p>"},{"location":"blog/2025/05/18/environment-setup/#docker-installation","title":"Docker installation","text":"<p>Following the official documentation :</p> <p>Setup the apt repository : <pre><code># Add Docker's official GPG key:\nsudo apt-get update\nsudo apt-get install ca-certificates curl\nsudo install -m 0755 -d /etc/apt/keyrings\nsudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\nsudo chmod a+r /etc/apt/keyrings/docker.asc\n\n# Add the repository to Apt sources:\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\n  $(. /etc/os-release &amp;&amp; echo \"${UBUNTU_CODENAME:-$VERSION_CODENAME}\") stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\nsudo apt-get update\n</code></pre></p> <p>At this step you should see an url from docker from the last command</p> <p>Install Docker package : <pre><code>sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n</code></pre></p> <p>Allowing non-root users to run docker commands (from documentation) : <pre><code>sudo groupadd docker\nsudo usermod -aG docker $USER\nnewgrp docker\n</code></pre></p> <p>It's pretty usefull to get auto-completion on Docker CLI following the official documentation :  </p> <ul> <li>Adding the right code snippet in the bashrc : <pre><code>cat &lt;&lt;EOT &gt;&gt; ~/.bashrc\nif [ -f /etc/bash_completion ]; then\n    . /etc/bash_completion\nfi\nEOT\n</code></pre></li> <li>Reloading the shell : <code>source ~/.bashrc</code></li> <li>Creating folder to store bash completion scripts <code>mkdir -p ~/.local/share/bash-completion/completions</code></li> <li>Generating the bash completion script for Docker <code>docker completion bash &gt; ~/.local/share/bash-completion/completions/docker</code></li> </ul> Click here if it worked <p></p>"},{"location":"blog/2025/05/18/environment-setup/#docker-swarm-init","title":"Docker swarm init","text":"<p>Let's initialize our Docker Swarm cluster : <pre><code>docker swarm init\n</code></pre></p> <p>Once the swarm cluster is setup we can start deploying things with ``</p>"},{"location":"blog/2026/01/22/fail2ban-installation-and-setup/","title":"Fail2Ban installation and setup","text":"<p>Fail2Ban scans log files like <code>/var/log/auth.log</code> and bans IP addresses conducting too many failed login attempts. It does this by updating system firewall rules to reject new connections from those IP addresses, for a configurable amount of time. Fail2Ban comes out-of-the-box ready to read many standard log files, such as those for sshd and Apache, and is easily configured to read any log file of your choosing, for any error you wish.</p> <p></p>"},{"location":"blog/2026/01/22/fail2ban-installation-and-setup/#installation","title":"Installation","text":"<p>Let's play a bunch of commands to install fail2ban !</p> <pre><code>sudo apt-get update\nsudo apt upgrade -y\n\nsudo apt install fail2ban\n</code></pre> <p>Fail2ban comes with default settings that work well for most users, but you can customize it to suit your needs. The main configuration file is located at /etc/fail2ban/jail.conf, but it\u2019s better to create a local copy for your custom settings to prevent overwriting during updates. Create a new file called jail.local: <pre><code>sudo cp /etc/fail2ban/jail.conf /etc/fail2ban/jail.local\nsudo nano /etc/fail2ban/jail.local\n</code></pre></p>"},{"location":"blog/2026/01/22/fail2ban-installation-and-setup/#configuration","title":"Configuration","text":""},{"location":"blog/2026/01/22/fail2ban-installation-and-setup/#ssh","title":"SSH","text":"<p>The default configuration is nice but let's twist it a bit !</p> <p>Firstly, the conditions to meet to be temporarly ban : /etc/fail2ban/jail.local<pre><code>bantime  = 10m\nfindtime  = 10m\nmaxretry = 5\n</code></pre></p> <p>Then we can configure the sshd jail: /etc/fail2ban/jail.local<pre><code>[sshd]\n\nport    = xxx # Being a custom port other than 22\nlogpath = /var/log/auth.log\nbackend = %(sshd_backend)s\n</code></pre></p> <p>By default, logs are handled by <code>journalctl</code>. We have to persist those logs :</p> <pre><code>cat /var/log/auth.log\nsudo apt-get install rsyslog\ncat /var/log/auth.log\n</code></pre> <p>Failed tries on existing user will not trigger a fail2ban \"fail\"</p> <p>To prevent false-positive with user using multiple sshkeys</p>"},{"location":"blog/2026/01/22/fail2ban-installation-and-setup/#authelia","title":"Authelia","text":"<p>Firstly, let's create a filter to store our beautiful regex :</p> /etc/fail2ban/filter.d/authelia.conf<pre><code># Fail2Ban filter for Authelia\n\n# Make sure that the HTTP header \"X-Forwarded-For\" received by Authelia's backend\n# only contains a single IP address (the one from the end-user), and not the proxy chain\n# (it is misleading: usually, this is the purpose of this header).\n\n# the failregex rule counts every failed 1FA attempt (first line, wrong username or password) and failed 2FA attempt\n# second line) as a failure.\n# the ignoreregex rule ignores info and warning messages as all authentication failures are flagged as errors\n# the third line catches incorrect usernames entered at the password reset form\n# the fourth line catches attempts to spam via the password reset form or 2fa device reset form. This requires debug logging to be enabled\n\n[Definition]\nfailregex = ^.*Unsuccessful (1FA|TOTP|Duo|U2F) authentication attempt by user .*remote_ip\"?(:|=)\"?&lt;HOST&gt;\"?.*$\n            ^.*user not found.*path=/api/reset-password/identity/start remote_ip\"?(:|=)\"?&lt;HOST&gt;\"?.*$\n            ^.*Sending an email to user.*path=/api/.*/start remote_ip\"?(:|=)\"?&lt;HOST&gt;\"?.*$\n\nignoreregex = ^.*level\"?(:|=)\"?info.*\n              ^.*level\"?(:|=)\"?warning.*\n</code></pre> <p>The we create and configure a new jail in <code>jail.local</code></p> /etc/fail2ban/jail.local<pre><code>[authelia]\nenabled = true\nport = http,https,9091\nfilter = authelia\nlogpath = /var/log/authelia/authelia.log\nchain = DOCKER-USER\n</code></pre> <p>Don't forget to persist authelia logs</p> <p>Usefull commands :</p> <pre><code>#To restart fail2ban\nsudo systemctl restart fail2ban.service\n\n#To get jail status\nsudo fail2ban-client status authelia\n</code></pre> <p>sshd works but not Authelia</p> <p>It appears that sshd ban remote IP, but for some reason, the authelia jail bans a local ip \"10.0.0.2\" instead of the ip of the sender. This issue has been addressed by setting the port mode to host for both 80 and 443 ports for the Traefik service.</p>"},{"location":"blog/2026/01/22/fail2ban-installation-and-setup/#visualisation","title":"Visualisation","text":"<p>With Alloy it is really easy to extract some data from a file. Luckily fail2ban stores everything we need in it's fail2ban.log file !</p> /var/log/fail2ban.log<pre><code>2026-01-18 00:03:52,228 fail2ban.filter         [2140643]: INFO    [sshd] Found 176.120.22.47 - 2026-01-18 00:03:51\n2026-01-18 00:04:13,306 fail2ban.filter         [2140643]: INFO    [sshd] Found 176.120.22.47 - 2026-01-18 00:04:13\n2026-01-18 00:05:02,978 fail2ban.filter         [2140643]: INFO    [sshd] Found 176.120.22.47 - 2026-01-18 00:05:02\n2026-01-18 00:05:14,955 fail2ban.filter         [2140643]: INFO    [sshd] Found 176.120.22.47 - 2026-01-18 00:05:14\n2026-01-18 00:05:27,767 fail2ban.filter         [2140643]: INFO    [sshd] Found 176.120.22.47 - 2026-01-18 00:05:27\n2026-01-18 00:05:27,919 fail2ban.actions        [2140643]: NOTICE  [sshd] Ban 176.120.22.47\n2026-01-18 00:15:27,472 fail2ban.actions        [2140643]: NOTICE  [sshd] Unban 176.120.22.47\n</code></pre>"},{"location":"blog/2026/01/22/fail2ban-installation-and-setup/#obtain-the-logs","title":"Obtain the logs","text":"<p>The first step is to locate and scarpe the file, this is easily done with the following components :  </p> config.alloy<pre><code>// Retrieve fail2ban logfile\nlocal.file_match \"fail2ban\" {\n    path_targets        = [{\n    __address__         = \"localhost\",\n    __path__            = \"/var/log/fail2ban.log\",\n    // __path_exclude__  = \"/var/log/fail2ban.log.*.gz\",\n    instance            = \"homelab\",\n    job                 = \"fail2ban\",\n  }]\n}\n\n// Scrape the file and send it to loki\nloki.source.file \"fail2ban\" {\n    targets    = local.file_match.fail2ban.targets\n    forward_to = [loki.process.fail2ban_get_ip.receiver]\n}\n</code></pre>"},{"location":"blog/2026/01/22/fail2ban-installation-and-setup/#extract-the-data-from-every-line","title":"Extract the data from every line","text":"<p>Fail2Ban does not build it's log with a convinient JSON format but with a regex we can extract the data we want and appending those data in labels to every log entry.</p> config.alloy<pre><code>// Process the log entries to extract data\nloki.process \"fail2ban_get_ip\" {\n    forward_to = [loki.process.fail2ban_geoip_lookup.receiver]\n\n    // Store in group desired data\n    stage.regex {\n        expression = \"^(?P&lt;time&gt;\\\\d{4}-\\\\d{2}-\\\\d{2} \\\\d{2}:\\\\d{2}:\\\\d{2},\\\\d{3})\\\\s+(?P&lt;fail2ban_component&gt;fail2ban\\\\.\\\\w+)\\\\s+\\\\[(?P&lt;pid&gt;\\\\d+)\\\\]:\\\\s+(?P&lt;level&gt;\\\\w+)\\\\s+\\\\[(?P&lt;jail&gt;[^\\\\]]+)\\\\]\\\\s+(?P&lt;action&gt;\\\\w+)\\\\s+(?P&lt;ip&gt;(?:\\\\d{1,3}\\\\.){3}\\\\d{1,3})?\"\n    }\n\n    // Define the time format for the \"time\" data retrieve in the log entry\n    stage.timestamp {\n        source = \"time\"\n        format = \"2006-01-02 15:04:05,000\"\n    }\n\n    // Natively associate every regex group with a label with the same name\n    stage.labels {\n        values = {\n            time      = \"\",\n            fail2ban_component = \"\",\n            jail      = \"\",\n            ip        = \"\",\n            action    = \"\",\n        }\n    }\n\n}\n</code></pre>"},{"location":"blog/2026/01/22/fail2ban-installation-and-setup/#from-ip-to-location","title":"From IP to Location","text":"<p>Thankfully Alloy already has <code>stage.geoip</code> within the <code>loki.process</code> component ! With this it's child's play :</p> config.alloy<pre><code>// Process the log entries to lookup data\nloki.process \"fail2ban_geoip_lookup\" {\n    forward_to = [loki.write.default.receiver]\n\n    // Lookup for each ip entry within the GeoLite2 database\n    stage.geoip {\n        db      = \"/usr/share/GeoLite2/GeoLite2-City.mmdb\"\n        source  = \"ip\"\n        db_type = \"city\"\n    }\n\n    // Natively associate every geoip output with a label with the same name\n    stage.labels {\n        values = {\n            geoip_city_name          = \"\",\n            geoip_country_name       = \"\",\n            // geoip_country_code       = \"\",\n            geoip_continent_name     = \"\",\n            // geoip_continent_code     = \"\",\n            geoip_location_latitude  = \"\",\n            geoip_location_longitude = \"\",\n        }\n    }\n}\n</code></pre> <p>You can only set 15 labels for each entry, remove the useless ones</p>"},{"location":"blog/2026/01/22/fail2ban-installation-and-setup/#result-overview","title":"Result overview","text":"<p>This is what the above parts do</p> Raw entryScraped entryIP extractedLocation extracted <pre><code>2026-01-22 13:32:42,616 fail2ban.filter         [2140643]: INFO    [sshd] Found 91.202.233.33 - 2026-01-22 13:32:42\n</code></pre> <pre><code>timestamp: 2026-01-22T13:32:42.616669492Z,\nentry: 2026-01-22 13:32:42,616 fail2ban.filter         [2140643]: INFO    [sshd] Found 91.202.233.33 - 2026-01-22 13:32:42,\nlabels: {\n    filename=\"/var/log/fail2ban.log\",\n    instance=\"homelab\",\n    job=\"fail2ban\"\n    },\nstructured_metadata: {}\n</code></pre> <pre><code>timestamp: 2026-01-22T13:32:42.616669492Z,\nentry: 2026-01-22 13:32:42,616 fail2ban.filter         [2140643]: INFO    [sshd] Found 91.202.233.33 - 2026-01-22 13:32:42,\nlabels: {\n    action=\"Found\",\n    fail2ban_component=\"fail2ban.filter\",\n    filename=\"/var/log/fail2ban.log\",\n    instance=\"homelab\",\n    ip=\"91.202.233.33\",\n    jail=\"sshd\",\n    job=\"fail2ban\",\n    time=\"2026-01-22 13:32:42,616\"\n}, structured_metadata: {}\n</code></pre> <pre><code>timestamp: 2026-01-22T13:32:42.616669492Z,\nentry: 2026-01-22 13:32:42,616 fail2ban.filter         [2140643]: INFO    [sshd] Found 91.202.233.33 - 2026-01-22 13:32:42,\nlabels: {\n    action=\"Found\",\n    fail2ban_component=\"fail2ban.filter\",\n    filename=\"/var/log/fail2ban.log\",\n    geoip_continent_name=\"Europe\"\n    geoip_country_name=\"Russia\"\n    geoip_location_latitude=\"55.7386\"\n    geoip_location_longitude=\"37.6068\"\n    instance=\"homelab\",\n    ip=\"91.202.233.33\",\n    jail=\"sshd\",\n    job=\"fail2ban\",\n    time=\"2026-01-22 13:32:42,616\"\n},\nstructured_metadata: {}\n</code></pre>"},{"location":"blog/2026/01/22/fail2ban-installation-and-setup/#display-on-grafana","title":"Display on Grafana","text":"<p>For Grafana it's not hard, just some config and toggling the right settings!</p> <p>Do not forget to extract labels, and convert lat and long to number in \"Transformations\" !</p> The JSON for a neat Heatmap <pre><code>{\n\"id\": 48,\n\"type\": \"geomap\",\n\"title\": \"Fail2Ban GeoIP\",\n\"gridPos\": {\n    \"x\": 0,\n    \"y\": 0,\n    \"h\": 16,\n    \"w\": 18\n},\n\"fieldConfig\": {\n    \"defaults\": {\n    \"custom\": {\n        \"hideFrom\": {\n        \"tooltip\": false,\n        \"viz\": false,\n        \"legend\": false\n        }\n    },\n    \"mappings\": [],\n    \"thresholds\": {\n        \"mode\": \"absolute\",\n        \"steps\": [\n        {\n            \"color\": \"green\",\n            \"value\": null\n        }\n        ]\n    },\n    \"color\": {\n        \"mode\": \"thresholds\"\n    }\n    },\n    \"overrides\": []\n},\n\"transformations\": [\n    {\n    \"id\": \"extractFields\",\n    \"options\": {\n        \"delimiter\": \",\",\n        \"source\": \"labels\"\n    }\n    },\n    {\n    \"id\": \"convertFieldType\",\n    \"options\": {\n        \"conversions\": [\n        {\n            \"destinationType\": \"number\",\n            \"targetField\": \"geoip_location_latitude\"\n        }\n        ],\n        \"fields\": {}\n    }\n    },\n    {\n    \"id\": \"convertFieldType\",\n    \"options\": {\n        \"conversions\": [\n        {\n            \"destinationType\": \"number\",\n            \"targetField\": \"geoip_location_longitude\"\n        }\n        ],\n        \"fields\": {}\n    }\n    }\n],\n\"pluginVersion\": \"12.3.0\",\n\"targets\": [\n    {\n    \"datasource\": {\n        \"type\": \"loki\",\n        \"uid\": \"P8E80F9AEF21F6940\"\n    },\n    \"direction\": \"backward\",\n    \"editorMode\": \"builder\",\n    \"expr\": \"{job=\\\"fail2ban\\\", action=\\\"Found\\\"}\",\n    \"hide\": false,\n    \"legendFormat\": \"\",\n    \"queryType\": \"range\",\n    \"refId\": \"A\"\n    }\n],\n\"datasource\": {\n    \"type\": \"loki\",\n    \"uid\": \"P8E80F9AEF21F6940\"\n},\n\"options\": {\n    \"view\": {\n    \"allLayers\": true,\n    \"id\": \"coords\",\n    \"lat\": 45,\n    \"lon\": 0,\n    \"noRepeat\": true,\n    \"zoom\": 2,\n    \"shared\": false\n    },\n    \"controls\": {\n    \"showZoom\": false,\n    \"mouseWheelZoom\": true,\n    \"showAttribution\": false,\n    \"showScale\": false,\n    \"showMeasure\": false,\n    \"showDebug\": false\n    },\n    \"tooltip\": {\n    \"mode\": \"none\"\n    },\n    \"basemap\": {\n    \"config\": {\n        \"showLabels\": true,\n        \"theme\": \"auto\"\n    },\n    \"layer-tooltip\": true,\n    \"name\": \"Layer 0\",\n    \"noRepeat\": true,\n    \"type\": \"carto\"\n    },\n    \"layers\": [\n    {\n        \"config\": {\n        \"blur\": 20,\n        \"radius\": 15,\n        \"weight\": {\n            \"fixed\": 1,\n            \"max\": 1,\n            \"min\": 0\n        }\n        },\n        \"filterData\": {\n        \"id\": \"byRefId\",\n        \"options\": \"A\"\n        },\n        \"layer-tooltip\": true,\n        \"location\": {\n        \"latitude\": \"geoip_location_latitude\",\n        \"longitude\": \"geoip_location_longitude\",\n        \"mode\": \"coords\"\n        },\n        \"name\": \"Found\",\n        \"opacity\": 1,\n        \"tooltip\": true,\n        \"type\": \"heatmap\"\n    }\n    ]\n}\n}\n</code></pre>"},{"location":"blog/2025/05/13/hardware-overview/","title":"Hardware overview","text":"<p>This article explores the hardware of a scalable hosting service that use Docker Swarm for efficient container orchestration and a lot of storage for centralized data management. It evaluates various hardware options, including servers, networking equipment, and storage solutions.</p>"},{"location":"blog/2025/05/13/hardware-overview/#introduction","title":"Introduction","text":"<p>A complete satisfying homelab is more complex to setup than a Raspberry Pi, Docker and a domain name (even if it can suffice). For my project I have to think about the case/rack, the network hardware (router, switch and cable) and software (VPN), the computing hardware (SBC like RaspberryPi, TinyMiniMicro PC like Dell Optiplex, Mini-ITX motherboard with CPU, a big ass rackable 19\" Threadripper), the storage for OS and media and always keep an eye on the budget, which is not infinite.</p>"},{"location":"blog/2025/05/13/hardware-overview/#computing-unit","title":"Computing unit","text":"<p>To define most of the hardware we first have to find the processor we would like to use. The main concern is the power consumption and the capability to transcode video. Diving in the documentation, Jellyfin recommend the use of few specific processors : Intel Core i5-11400, Intel Pentium Gold G7400, Intel N100, Apple M series or newer (excluding Intel J/M/N/Y series up to 11<sup>th</sup> gen). On top of being great at transcoding for it power consumption, the N100 is frequently available already mounted on a mini-ITX motherboard. Through my research I found a lot of cheap chinese micro PC with N100 but those are limited mostly allowing 16 Go of memory limit and not suitable for a raid due to the lack of sata connections without easy solution.</p>"},{"location":"blog/2025/05/13/hardware-overview/#storage","title":"Storage","text":"<p>In this project, we're going to have two main types of storage.  </p> <p>Since the recommended memory for most OS + tools will be 32 Go and the need for fast drive, any kind of SSD will suffice.  </p> <p>And for \"media storage\", a RAID 5 array with 4 \\(\\times\\) 2 To WD Red Plus 2 To 3.5\" HDD at 5400 RPM disks is used today on the current homelab. This kind of RAID is convenient because this kind of array combines flexibility, security and the can easily be expanded.  </p>"},{"location":"blog/2025/05/13/hardware-overview/#hardware","title":"Hardware","text":""},{"location":"blog/2025/05/13/hardware-overview/#already-available-hardware","title":"Already available hardware","text":"<p>Build 1 : - case : Aerocool vs1 - psu : Corsair RM750x - motherboard : MSI 990FXA gaming - RAM : G.SKILL ripjawsZ DDR3 4 Go \\times 4 = 16 Go - GPU : MSI RX 480 4G - CPU : AMD FX-8370 @4.00GHz - CPU fan : be quiet Pure wings 2</p> <p>Build 2 : - case : Enermax Skalene  - psu : Corsair HX750i - motherboard : MSI Z97 Gaming 5 - RAM : G.SKILL ripjawsZ DDR3 4 Go \\times 4 = 16 Go - GPU : GTX 1060 3Go - CPU : i7-4790 @ 3.60GHz - CPU fan : be quiet</p> <p>TurboNAS build : - case : Zalman Z1 neo - psu : Corsair CS650M - motherboard : Asus Z97 pro gamer - GPU : N/A - RAM : 32 Go - CPU : i7-4790K @ 4.00GHz - CPU fan : Ventirad Noctua</p> <p>Miscellaneous : - Raspberry PI 2B - Raspberry PI 4B 8Go - Samsung SSD 850 Pro 256 Go - 2 \\times Seagate Desktop HDD 2 To - DELL Vostro 200 (Intel Core 2 Duo E6320, 6 Go DDR2-SDRAM, HDD 160 Go)</p>"},{"location":"blog/2025/05/13/hardware-overview/#possible-hardware","title":"Possible hardware","text":"<p>GeeekPi 8U Server Rack DeskPi RackMate T1 for 170 \u20ac</p> <p>DIGITUS Network cabinet 10 inch - 12U for 110 \u20ac</p> <p>10\" racks are cute but expensive and add a lot of constraints to be modular and as much dust-free as possible.</p>"},{"location":"blog/2025/05/13/hardware-overview/#bought-hardware","title":"Bought hardware","text":"Hardware Price Motherboard : ASRock N100DC-ITX 146 \u20ac DC jack 5,5 x 2,5 mm 3 \u20ac Crucial RAM DDR4 32GB 3200MHz 57\u20ac M.2 to 6 SATA ports 30 \u20ac 5.25 Inch to 5 X 3.5 Inch SATA HDD Cage Rack 27 \u20ac Total 263 \u20ac"},{"location":"blog/2025/05/13/hardware-overview/#final-hardware","title":"Final hardware","text":"<ul> <li>case : Aerocool vs1</li> <li>psu : Corsair HX750i</li> <li>motherboard : ASRock N100DC-ITX</li> <li>GPU : None</li> <li>RAM : Crucial RAM DDR4 32GB 3200MHz</li> <li>CPU : Intel N100</li> <li>CPU fan : Passive</li> </ul>"},{"location":"blog/2026/01/16/monitoring/","title":"Monitoring","text":"<p>Setting up a monitoring stack for a homelab is critical to ensuring optimal performance, reliability, and security. It allows you to track resource usage, perform health checks, and troubleshoot problems  issues, minimizing downtime. Overall, a robust monitoring setup is essential for maintaining a well-functioning and efficient homelab.</p>"},{"location":"blog/2026/01/16/monitoring/#requirements-definition","title":"Requirements definition","text":"<p>Monitoring the infrastructure and applications is critical to detect potential hardware problems or limitations, have security insight (e.g. brut-force attacks) and to track application resource consumption. For both the system and containers I want to monitor CPU, RAM, Disks (including RAID) usage and capacity. I also want as well to retrieve system and applicative logs. I would also like to be able to implement geographical fail2ban statistics and finally, for application providing it, it would be nice to export applicatives metrics.</p> Metrics Metrics are all the measurements that are taken on the server. From RAM usage to fan speed to processor temperature, everything can be measured on a machine (using hwinfo for example). In this section, we'll look at ways of collecting this data and making it available to a viewing tool."},{"location":"blog/2026/01/16/monitoring/#tools","title":"Tools","text":""},{"location":"blog/2026/01/16/monitoring/#grafana-and-more","title":"Grafana and more","text":"<p>The Grafana stack consists of several tools, some to retrieve metrics or logs, some to store those data and Grafana to visualise it all.</p> Node-exporter As its name suggests, Node-exporter allows you to collect metrics from your Linux environment and export them to a timeseries-type database (e.g. Prometheus). cAdvisor cAdvisor, which stands for Container Advisor, is an open source tool developed by Google. It monitors the metrics of each container, such as network, memory, CPU consumption, etc. and then exports them to the database (Prometheus). Prometheus Prometheus can be thought of as a metrics database that makes the metrics collected by Node-Exporter and cAdvisor available to Grafana. Promtail Promtail collects and sends logs (system, applicative, any logs) to be stored in Loki. Loki Loki is like Prometheus but for logs. It stores and makes available the logs sent by the loki-docker-driver and Promtail plugins. loki-docker-driver Grafana Loki officially supports a Docker plugin that reads logs from Docker containers and sends them to Loki. Grafana Grafana is a tool for displaying data from just almost anywhere. It lets you create dashboards from a variety of tiles, including graphs, curves, histograms, logs, text, maps and more.   <p>This stack will allow me to monitor my homelab in great detail. It could also be a great showcase for my skills.</p>"},{"location":"blog/2026/01/16/monitoring/#dozzle","title":"Dozzle","text":"<p>Dozzle is a simple, effective and lightweight alternative for viewing container logs, instant metrics and for interacting with containers. The speed and simplicity of this tool will gives me a quick overview of the logs and metrics of my containers.</p>"},{"location":"blog/2026/01/16/monitoring/#uptime-kuma","title":"Uptime Kuma","text":"<p>Uptime Kuma is a fancy, easy-to-use uptime monitoring tool. I will use this tool to set up a dashboard to get an insight into the uptime of my services.</p>"},{"location":"blog/2026/01/16/monitoring/#deprecation-and-new-tool","title":"Deprecation and new tool","text":"<p>Since I write the first par of this post, I learned that Promtail got deprecated and is being replaced by Grafana Alloy.</p> <p>On top of the replacement of Promtail, Alloy has been conceived to allow metrics, logs and trace collection from different sources. From my research I seems that Alloy could replace Node-Exporter, CAdvisor and loki-docker-drive.</p> <p></p>"},{"location":"blog/2026/01/16/monitoring/#alloy-implementation","title":"Alloy implementation","text":""},{"location":"blog/2026/01/16/monitoring/#alloy-setup","title":"Alloy Setup","text":"<p>Let's follow the official documentation !</p> <p>The first thing we have to do is to create a config.alloy file</p> config.alloy<pre><code>logging {\n  level  = \"info\"\n  format = \"logfmt\"\n}\n</code></pre> <p>Now we have to convert the docker run command in a pretty swarm service :</p> <p>Docker setup</p> docker rundocker swarm <pre><code>docker run \\\n-v &lt;CONFIG_FILE_PATH&gt;:/etc/alloy/config.alloy \\\n-p 12345:12345 \\\ngrafana/alloy:latest \\\n    run --server.http.listen-addr=0.0.0.0:12345 --storage.path=/var/lib/alloy/data \\\n    /etc/alloy/config.alloy\n</code></pre> <pre><code>alloy:\n  image: grafana/alloy:v1.12.2\n  deploy:\n    replicas: 1\n  volumes:\n    - ./alloy/config.alloy:/etc/alloy/config.alloy\n  command:\n    - run\n    - /etc/alloy/config.alloy\n    - --server.http.listen-addr=0.0.0.0:12345\n    - --storage.path=/var/lib/alloy/data\n  ports:\n    - 12345:12345\n</code></pre> <p>Once the service is up, we can access to a really simple but helpful UI.</p>"},{"location":"blog/2026/01/16/monitoring/#making-alloy-ready","title":"Making Alloy ready","text":"<p>The previous Docker stack isn't enough to run Alloy in \"prod\". We have to improve it a bit.</p> stack.yaml<pre><code>services:\n  alloy:\n    image: grafana/alloy:v1.12.2\n    deploy:\n      replicas: 1\n    labels:\n        traefik.enable: \"true\"\n        traefik.http.services.alloy.loadbalancer.server.port: 12345\n        traefik.http.routers.alloy.rule: Host(`alloy.lsarlinmagnus.fr`)\n        traefik.http.routers.alloy.entrypoints: websecure\n        traefik.http.routers.alloy.tls: \"true\"\n        traefik.http.routers.alloy.tls.certresolver: ovh\n        traefik.http.routers.alloy.middlewares: authelia@file\n        homepage.group: Monitoring\n        homepage.name: Alloy\n        homepage.icon: alloy.png\n        homepage.href: https://alloy.lsarlinmagnus.fr\n    configs:\n      - source: alloy_config\n        target: /etc/alloy/config.alloy\n    volumes:\n      - /:/rootfs:ro\n      - /run:/run:ro\n      - /var/log:/var/log:ro\n      - /sys:/sys:ro\n      - /var/lib/docker/:/var/lib/docker/:ro\n      - /run/udev/data:/run/udev/data:ro    \n    command:\n      - run\n      - /etc/alloy/config.alloy\n      - --server.http.listen-addr=0.0.0.0:12345\n      - --storage.path=/var/lib/alloy/data\n    networks:\n      - proxy\n\nconfigs:\n  alloy_config:\n    file: ./alloy/config.alloy\n\nnetworks:\n  proxy:\n    external: true\n</code></pre>"},{"location":"blog/2026/01/16/monitoring/#alloy-configuration","title":"Alloy configuration","text":"<p>Alloy is configured within the <code>config.alloy</code> file. The configuration is build using \"components\".</p> config.alloy<pre><code>\n</code></pre> <p>We can visualize the result in Grafana &gt; Drilldown</p>"},{"location":"blog/2026/01/16/monitoring/#conclusion","title":"Conclusion","text":"<p>With all these tools I will be able to have a quick look at my logs, a view on the uptime and a deep knowledge of what's happening in my homelab !</p>"},{"location":"blog/2025/03/10/container-orchestration/","title":"Container orchestration","text":"<p>In a homelab environment, selecting the most suitable container orchestration tool is crucial for optimizing experimentation and management. This article compares Docker Compose, Docker Swarm, Kubernetes light distribution (like K0S and Minikube), and Kubernetes to identify the best fit for my use case. Docker Compose simplifies multi-container setups while Docker Swarm provides straightforward clustering and scaling, and K0S and Minikube offer lightweight Kubernetes experiences for testing and learning.</p>"},{"location":"blog/2025/03/10/container-orchestration/#definitions","title":"Definitions","text":"Docker Compose A tool for defining and running multi-container Docker applications using a simple YAML file to configure services, networks, and volumes. Docker Swarm Docker's native clustering and orchestration tool that allows you to manage a group of Docker engines as a single virtual system for deploying applications. Lightweight Kubernetes distributions (K0s, K3s, minikube, etc.) Simplified versions of Kubernetes designed for local development or small-scale deployments, making it easy to run Kubernetes clusters on personal machines. Kubernetes An open-source container orchestration platform that automates the deployment, scaling, and management of containerized applications across clusters of machines."},{"location":"blog/2025/03/10/container-orchestration/#general-comparison","title":"General comparison","text":"Feature/Aspect Docker Compose Docker Swarm Lightweight Kubernetes Kubernetes Purpose Define and run multi-container apps Cluster management and orchestration Local development and testing Full-scale container orchestration Complexity Simple and easy to use Moderate complexity Low complexity High complexity Deployment Scale Best for single-host applications Multi-host, but simpler than Kubernetes Local or small clusters Large-scale, production-grade clusters Networking Basic networking capabilities Built-in overlay networking Basic networking Advanced networking features State Management Stateless by default Supports stateful services Limited state management Robust state management with persistent storage Use Case Development and testing Simple production deployments Local development and experimentation Production environments and complex applications Learning Curve Low Moderate Low High"},{"location":"blog/2025/03/10/container-orchestration/#key-features-rating","title":"Key features rating","text":"Drivers Docker Compose Docker Swarm Lightweight Kubernetes Kubernetes Ease of use ***** **** *** ** Leaning goals * **** *** ** Resource efficiency **** **** *** * Documentation and community **** **** *** ***** Ease of maintenance ***** ***** *** *** Ease of evolution ***** ***** ** ** Total 24 26 17 15"},{"location":"blog/2025/03/10/container-orchestration/#detailed-pros-and-cons","title":"Detailed Pros and cons","text":""},{"location":"blog/2025/03/10/container-orchestration/#docker-compose","title":"Docker Compose","text":"<p>On my previous (actual at the time i'm writing this) NAS I used Docker Compose to deploy my services. Docker Compose allow the definition of the deployments in a simple <code>docker-compose.yaml</code> file and with minimal configuration. I consider Docker Compose as an easy and efficient way to deploy stuff but it can lack some features.</p> Pros <ul> <li>Easy to use and setup</li> </ul> <ul> <li>Easy deployment declaration</li> </ul> Cons <ul> <li>Not really an orchestrator</li> </ul> <ul> <li>Already known</li> </ul> <ul> <li>Limited to single-host deployments</li> </ul>"},{"location":"blog/2025/03/10/container-orchestration/#docker-swarm","title":"Docker Swarm","text":"<p>Docker Swarm is a native clustering and orchestration tool for Docker. It provides more feature that Docker Compose like load balancing, service discovery, and scaling for containerized applications.</p> Pros <ul> <li>Easy to use and setup</li> </ul> <ul> <li>Built-in load balancing and service discovery</li> </ul> Cons <ul> <li>Less feature than Kubernetes</li> </ul> <ul> <li>Potential leaning experience (Never used neither as a hobby nor at work)</li> </ul>"},{"location":"blog/2025/03/10/container-orchestration/#lightweight-kubernetes","title":"Lightweight Kubernetes","text":"<p>Lightweight Kubernetes are designed to provide a simplified Kubernetes experience for local development and testing. It provide a way to run Kubernetes clusters on a local machines with minimal setup and resource requirements.</p> Pros <ul> <li>Easy to use and setup</li> </ul> <ul> <li>Provides simplified Kubernetes experience</li> </ul> Cons <ul> <li>Less featured than Kubernetes</li> </ul> <ul> <li>For testing and developing purpose (not for prod in theory)</li> </ul>"},{"location":"blog/2025/03/10/container-orchestration/#kubernetes","title":"Kubernetes","text":"<p>Kubernetes automates the deployment, scaling, and management of containerized applications across clusters of hosts. It offers advanced features like self-healing, load balancing, and service discovery.</p> Pros <ul> <li>Highly scalable and robust</li> </ul> <ul> <li>Huge ecosystem, tools and plugins</li> </ul> Cons <ul> <li>More complex to setup</li> </ul> <ul> <li>Less resource efficient</li> </ul>"},{"location":"blog/2025/03/10/container-orchestration/#conclusion","title":"Conclusion","text":"<p>I will use Docker Swarm to orchestrate my services for two main reasons. Firstly, Docker Swarm is something I had never use despite my curiosity for this tool since years . Secondly, Docker Swarm is easy to setup, use and maintain and therefore is perfectly adapted to homelabs.</p>"},{"location":"blog/2026/02/03/power-consumption/","title":"Power consumption","text":"<p>With this beautiful monitoring stack and all the effort I put on the system optimisation to make the homelab power efficient, it is a nice feature to monitor the power draw from the wall.</p>"},{"location":"blog/2026/02/03/power-consumption/#measurment-methods","title":"Measurment methods","text":"<p>To measure power consumption there is 2 main methods. The hardware one and the software extrapolation one. The hardware measure is more accurate but it cost more and add add work to retrieve the data. The software method is cheaper but is not accurate and ask for a lot of tests combined with hardware to be sure that every component is taken into account in the measure (e.g. the motherboard can give a gross value but it did not include the psu)</p> <p>For reasons of accuracy I will do the hardware method.</p> <p>There is a lot of cheap and expensive powermeter with a wide range of feature. The key points for my project are that I don't want those data to end up on a proprietary cloud and I want something tinker-ready.</p> <p>During my search I found Shelly. Shelly is a Bulgarian brand that produce a lot of range of smart things to automate your home (switches, plugs, sensors, etc.) with a heavy focus on : - No cloud required: Control your Shelly devices locally without connecting them to an external cloud or server - Highly compatible: Shelly devices are compatible with most home automation platforms, protocols and voice assistants</p> <p>I choose the Shelly Plug S Gen3 for it versatility.</p>"},{"location":"blog/2026/02/03/power-consumption/#collecting-those-data","title":"Collecting those data","text":""},{"location":"blog/2026/02/03/power-consumption/#relying-on-the-api","title":"Relying on the api","text":"<p>Once setup, I can access the smart plug's web UI directly on the IP http://192.168.1.45/#/scripts. the purpose of this webUI is configuring the smart plug. However Shelly has thought of everything by giving us access to an API to interact directly with the plug http://192.168.1.45/rpc/shelly.GetStatus.</p> <p>Mainly because I'm lazy I tried to use alloy to retrieve the metrics directly using the API.</p> <p>The most advanced step I went was retrieving a value but Alloy won't let me convert a float64 to a string :</p> <p>config.alloy<pre><code>// Defining Shelly API\nremote.http \"shelly_api\" {\n  url = \"http://192.168.1.45/rpc/Switch.GetStatus?id=0\"\n  poll_frequency = \"10s\"\n  poll_timeout = \"5s\"\n}\n\n// Scraping Shelly API\nprometheus.scrape \"default\" {\n  targets    = json_path(remote.http.shelly_api.content, \".aenergy.total\")\n  forward_to = [prometheus.remote_write.default.receiver]\n\n  scrape_interval = \"10s\"\n}\n</code></pre> Resulting in :</p> <pre><code>Error: /etc/alloy/config.alloy:284:16: json_path(remote.http.shelly_api.content, \".aenergy.total\")[0] target::ConvertFrom: conversion from 'float64' is not supported\n283 | prometheus.scrape \"default\" {\n284 |   targets    = json_path(remote.http.shelly_api.content, \".aenergy.total\")\n    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n285 |   forward_to = [prometheus.remote_write.default.receiver]\ninterrupt received\n\n    ts=2026-02-03T09:08:48.062393434Z\n    level=error\n    msg=failed to evaluate config\n    controller_path=/\n    controller_id=\n    node=prometheus.scrape.default\n    err=decoding configuration: /etc/alloy/config.alloy:284:16: json_path(remote.http.shelly_api.content, \\\".aenergy.total\\\")[0] target::ConvertFrom: conversion from 'float64' is not supported\n\nError: could not perform the initial load successfully\n</code></pre>"},{"location":"blog/2026/02/03/power-consumption/#setting-up-a-script","title":"Setting up a script","text":"<p>Hopefully, Shelly make it possible to write script directly within the smart plug ! In the library I found a ready-to-use script that does exactly what I want. The problem is that the plug has a realy limited hardware and can't event run this little script. I had to optimize it the best I could.</p> <pre><code>/**\n * @title Prometheus HTTP Endpoint for a single switch\n * @description This script exposes a /status endpoint that returns Prometheus metrics.\n */\n\n// Configuration\nconst metric_prefix = \"shelly_\";\nconst url = \"metrics\";\nconst monitored_switches = [\"switch:0\"];\nconst TYPE_GAUGE = \"gauge\";\nconst TYPE_COUNTER = \"counter\";\n\n// Device info\nconst info = Shelly.getDeviceInfo();\n\n// Helper function to format labels\nfunction promLabel(label, value) {\n  return label + '=\"' + value + '\"';\n}\n\n// Default labels for all metrics\nconst defaultLabels = [\n  promLabel(\"placement\", \"homelab\"),\n  promLabel(\"id\", info.id)\n];\n\n// Generate a Prometheus metric string\nfunction printPrometheusMetric(name, type, description, value) {\n  let labels = defaultLabels.join(\",\");\n  return (\n    \"# HELP \" + metric_prefix + name + \" \" + description + \"\\n\" +\n    \"# TYPE \" + metric_prefix + name + \" \" + type + \"\\n\" +\n    metric_prefix + name + \"{\" + labels + \"} \" + value + \"\\n\"\n  );\n}\n\n// HTTP handler\nfunction httpServerHandler(request, response) {\n  response.body = generateMetricsForSystem();\n  for (let i = 0; i &lt; monitored_switches.length; i++) {\n    response.body += generateMetricsForSwitch(monitored_switches[i]);\n  }\n  response.code = 200;\n  response.headers = [['Content-Type', 'text/plain; version=0.0.4']];\n  response.send();\n}\n\n// Generate system metrics\nfunction generateMetricsForSystem() {\n  const sys = Shelly.getComponentStatus(\"sys\");\n  let metrics = \"\";\n  metrics += printPrometheusMetric(\"uptime_seconds\", TYPE_COUNTER, \"Uptime in seconds\", sys.uptime) + \"\\n\";\n  metrics += printPrometheusMetric(\"ram_size_bytes\", TYPE_GAUGE, \"Internal board RAM size in bytes\", sys.ram_size) + \"\\n\";\n  metrics += printPrometheusMetric(\"ram_free_bytes\", TYPE_GAUGE, \"Internal board free RAM size in bytes\", sys.ram_free) + \"\\n\";\n  return metrics;\n}\n\n// Generate switch metrics\nfunction generateMetricsForSwitch(string_id) {\n  const sw = Shelly.getComponentStatus(string_id);\n  let metrics = \"\";\n  metrics += printPrometheusMetric(\"switch_power_watts\", TYPE_GAUGE, \"Instant power consumption in watts\", sw.apower) + \"\\n\";\n  metrics += printPrometheusMetric(\"switch_voltage_volts\", TYPE_GAUGE, \"Instant voltage in volts\", sw.voltage) + \"\\n\";\n  metrics += printPrometheusMetric(\"switch_current_amperes\", TYPE_GAUGE, \"Instant current in amperes\", sw.current) + \"\\n\";\n  metrics += printPrometheusMetric(\"switch_temperature_celsius\", TYPE_GAUGE, \"Temperature of the plug in celsius\", sw.temperature.tC) + \"\\n\";\n  metrics += printPrometheusMetric(\"switch_power_total\", TYPE_COUNTER, \"Accumulated energy consumed in watt-hours\", sw.aenergy.total) + \"\\n\";\n  metrics += printPrometheusMetric(\"switch_output\", TYPE_GAUGE, \"Is switch (1) on or (0) off\", sw.output ? 1 : 0) + \"\\n\";\n  return metrics;\n}\n\n// Register the HTTP endpoint\nHTTPServer.registerEndpoint(url, httpServerHandler);\n</code></pre> <p>Once the metrics exposed, it's child's play to scrape it with Alloy :</p> config.alloy<pre><code>\n</code></pre>"},{"location":"blog/2026/02/03/power-consumption/#conclusion","title":"Conclusion","text":"<p>This little challenge was quite funny and I think this will evolve someday because I plan to dive in the domotic world !</p>"},{"location":"blog/2026/01/06/raid-5-relocation/","title":"RAID 5 relocation","text":"<p>It's time to relocate the good old RAID 5 to the new homelab server</p>"},{"location":"blog/2026/01/06/raid-5-relocation/#definition","title":"Definition","text":"<p>RAID 5 consists of block-level striping with distributed parity. Unlike in RAID 4, parity information is distributed among the drives. It requires that all drives but one be present to operate. Upon failure of a single drive, subsequent reads can be calculated from the distributed parity such that no data is lost.</p>"},{"location":"blog/2026/01/06/raid-5-relocation/#context","title":"Context","text":"<p>The RAID5 is constituted of four 2To HDD NAS Hard drive (WD Red Plus 2TB Internal Hard Drive 3.5\" Dedicated NAS, 5400 RPM Class, SATA 6 GB/s, CMR, 64MB Cache). The RAID is known under the name md0.</p> <p>To add a bit of challenge, thee server is randomly rebooting for unknown reasons</p>"},{"location":"blog/2026/01/06/raid-5-relocation/#procedure","title":"Procedure","text":"<p>First let's retrieve some informations about the actual installation</p> <pre><code>louison@turbonas:~/turbonas$ sudo mdadm --detail /dev/md0\n/dev/md0:\n           Version : 1.2\n     Creation Time : Wed Nov  2 23:45:02 2022\n        Raid Level : raid5\n        Array Size : 5860144128 (5588.67 GiB 6000.79 GB)\n     Used Dev Size : 1953381376 (1862.89 GiB 2000.26 GB)\n      Raid Devices : 4\n     Total Devices : 4\n       Persistence : Superblock is persistent\n\n     Intent Bitmap : Internal\n\n       Update Time : Sat Jan  3 22:06:21 2026\n             State : clean \n    Active Devices : 4\n   Working Devices : 4\n    Failed Devices : 0\n     Spare Devices : 0\n\n            Layout : left-symmetric\n        Chunk Size : 512K\n\nConsistency Policy : bitmap\n\n              Name : turbonas:0  (local to host turbonas)\n              UUID : 694560c2:f5cfb9ed:f9b426fe:a0647876\n            Events : 167869\n\n    Number   Major   Minor   RaidDevice State\n       0       8       33        0      active sync   /dev/sdc1\n       1       8       49        1      active sync   /dev/sdd1\n       3       8       65        2      active sync   /dev/sde1\n       5       8        1        3      active sync   /dev/sda1\n</code></pre> <pre><code>louison@turbonas:~/turbonas$ cat /etc/fstab\n# /etc/fstab: static file system information.\n#\n# Use 'blkid' to print the universally unique identifier for a\n# device; this may be used with UUID= as a more robust way to name devices\n# that works even if disks are added and removed. See fstab(5).\n#\n# &lt;file system&gt; &lt;mount point&gt;   &lt;type&gt;  &lt;options&gt;       &lt;dump&gt;  &lt;pass&gt;\n# / was on /dev/ubuntu-vg/ubuntu-lv during curtin installation\n/dev/disk/by-id/dm-uuid-LVM-kGozoEGlUCJzlum3ZYoECbC80V2ffiJ22ewGtR7F8qJaMheALEnxEst1ZJd02LMS / ext4 defaults 0 1\n# /boot was on /dev/sdb2 during curtin installation\n/dev/disk/by-uuid/514a4d2e-8fe6-4202-9579-927d20091322 /boot ext4 defaults 0 1\n# /boot/efi was on /dev/sdb1 during curtin installation\n/dev/disk/by-uuid/1767-5EBF /boot/efi vfat defaults 0 1\n#/swap.img      none    swap    sw      0       0\n/dev/md0    /media/raid    ext4    defaults    0    1\n</code></pre> <p>When I plugged the disks into the new server, I faced an issue with one disk. After testing data cable and power cable, I concluded that the issue was comming from the chinese M2 6SATA adapter.</p> <p>Once I get all the disks connected, by some miracle, when I found out that the RAID had been automatically assemnbled.</p> <p>Finally, I had to mount the RAID to the desired location and persist this mount in fstab.</p>"},{"location":"blog/2025/04/01/software-need-definition/","title":"Software need definition","text":"<p>What is the purpose of a beautiful rack full of hardware without any software to run or service to host ?</p>"},{"location":"blog/2025/04/01/software-need-definition/#the-docker-services-i-want-to-host","title":"The Docker services I want to host","text":"<p>I will use Dowker Swarm as my orchestrator, here is the services I need split in stacks.</p>"},{"location":"blog/2025/04/01/software-need-definition/#admin-stack","title":"admin stack","text":"<p>This stack contains the administration tool useful to secure the homelab and give access to users</p> <ul> <li>Reverse-proxy : Traefik</li> <li>Protection against malicious IPs : crowdsec</li> <li>SSO (single-sign on) : Authelia</li> <li>Identity provider : LLDAP</li> </ul>"},{"location":"blog/2025/04/01/software-need-definition/#core-stack","title":"core stack","text":"<p>This stack is dedicated to cool stuff to manage the homelab</p> <ul> <li>Dashboard : Homepage</li> <li>Notifying tool : Gotify</li> <li>Updates : Watchtower</li> <li>Auto-pause Container : Sablier</li> </ul>"},{"location":"blog/2025/04/01/software-need-definition/#pictures-stack","title":"pictures stack","text":"<p>This stack is for all my services related to pictures storing and sharing?</p> <ul> <li>Photo manager : Immich<ul> <li>immich machine learning</li> <li>postgreSQL</li> <li>redis</li> </ul> </li> </ul>"},{"location":"blog/2025/04/01/software-need-definition/#media-stack","title":"media stack","text":"<p>The stack to automate and serve media</p> <ul> <li>Media server : Jellyfin</li> <li>The *arr suite :<ul> <li>Requests : Jellyseerr</li> <li>TV shows : Sonarr</li> <li>Movies : Radarr</li> <li>Indexer manager : Jackett</li> <li>Torrent client : qBittorrent</li> <li>Solve challenges : FlareSolverr</li> <li>Stalled torrents remover : Decluttarr</li> <li>Profile manager : Profilarr</li> <li>Transcoding automation : Tdarr</li> </ul> </li> </ul>"},{"location":"blog/2025/04/01/software-need-definition/#documents-stack","title":"documents stack","text":"<p>To manage PDF</p> <ul> <li>Document manager : Paperless-ngx</li> <li>postgreSQL</li> <li>PDF tool : Stirling PDF</li> </ul>"},{"location":"blog/2025/04/01/software-need-definition/#networking-stack","title":"networking stack","text":"<p>A little stack to do network stuff</p> <ul> <li>Ad blocker : Blocky</li> </ul>"},{"location":"blog/2025/04/01/software-need-definition/#monitoring-stack","title":"monitoring stack","text":"<p>To monitor my homelab</p> <ul> <li>Grafana<ul> <li>Prometheus</li> <li>cAdvisor</li> <li>node-exporter</li> <li>fail2ban-prometheus-exporter</li> <li>Promtail</li> <li>Loki</li> </ul> </li> <li>Centralized logging : Dozzle</li> <li>Uptime monitoring : uptime-kuma</li> </ul>"},{"location":"blog/2025/04/01/software-need-definition/#miscellaneous-stack","title":"miscellaneous stack","text":"<p>This stack will hold other services</p> <ul> <li>Password manager : Vaultwarden</li> </ul>"},{"location":"blog/2025/04/01/software-need-definition/#the-system-tools-i-need-to-install-directly-on-the-os","title":"The system tools I need to install directly on the OS","text":"<ul> <li>Network security daemon : fail2ban</li> <li>Driver to export system logs : loki-docker-driver</li> </ul>"},{"location":"cheatsheet/","title":"Index","text":""},{"location":"cheatsheet/#markdown-cheatsheet","title":"Markdown Cheatsheet","text":"<p>Markdown is key in documentation to present and display information in the best way possible. This section focus on how to write Markdown and how to use Markdown extensions for doing this kind of things :</p> <p>That's a big pile of Markdown extensions</p> BashCC++C# <p>This is some bash script, it is a cutting edge technology ain't much but it's honest work !  <pre><code>#!/bin/bash\necho \"Hello world!\"\n</code></pre></p> <pre><code>#include &lt;stdio.h&gt;\nint main(void) {\n    printf(\"Hello world!\\n\");\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\nint main() {\n    std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n    return 0;\n}\n</code></pre> <pre><code>using System;\nclass Program {\n    static void Main(string[] args) {\n    Console.WriteLine(\"Hello world!\");\n    }\n}\n</code></pre> Spoiler alert <p>It's not that difficult !! </p>"},{"location":"cheatsheet/diagrams/","title":"Diagrams","text":""},{"location":"cheatsheet/diagrams/#diagrams-mermaid","title":"Diagrams Mermaid","text":"<p>To create diagrams, mkdocs relies on Mermaid.js</p>"},{"location":"cheatsheet/diagrams/#flowchart","title":"Flowchart","text":"<p>Flowchart</p> AspectCode <pre><code>graph LR\nA[Start] --&gt; B{Error?};\nB --&gt;|Yes| C[Hmm...];\nC --&gt; D[Debug];\nD --&gt; B;\nB ----&gt;|No| E[Yay!];</code></pre> <pre><code>``` mermaid\ngraph LR\nA[Start] --&gt; B{Error?};\nB --&gt;|Yes| C[Hmm...];\nC --&gt; D[Debug];\nD --&gt; B;\nB ----&gt;|No| E[Yay!];\n```\n</code></pre>"},{"location":"cheatsheet/diagrams/#sequence-diagram","title":"Sequence diagram","text":"<p>Flowchart</p> AspectCode <pre><code>    sequenceDiagram\n        participant Alice\n        participant Bob\n        Alice-&gt;&gt;John: Hello John, how are you?\n        loop Healthcheck\n            John-&gt;&gt;John: Fight against hypochondria\n        end\n        John--&gt;&gt;Alice: Great!\n        John-&gt;&gt;Bob: How about you?\n        Bob--&gt;&gt;John: Jolly good!</code></pre> <pre><code>```mermaid\nsequenceDiagram\n    participant Alice\n    participant Bob\n    Alice-&gt;&gt;John: Hello John, how are you?\n    loop Healthcheck\n        John-&gt;&gt;John: Fight against hypochondria\n    end\n    John--&gt;&gt;Alice: Great!\n    John-&gt;&gt;Bob: How about you?\n    Bob--&gt;&gt;John: Jolly good!\n```\n</code></pre>"},{"location":"cheatsheet/diagrams/#state-diagrams","title":"State diagrams","text":"<p>State diagrams</p> AspectCode <pre><code>stateDiagram-v2\nstate fork_state &lt;&lt;fork&gt;&gt;\n    [*] --&gt; fork_state\n    fork_state --&gt; State2\n    fork_state --&gt; State3\n\n    state join_state &lt;&lt;join&gt;&gt;\n    State2 --&gt; join_state\n    State3 --&gt; join_state\n    join_state --&gt; State4\n    State4 --&gt; [*]</code></pre> <pre><code>``` mermaid\nstateDiagram-v2\nstate fork_state &lt;&lt;fork&gt;&gt;\n    [*] --&gt; fork_state\n    fork_state --&gt; State2\n    fork_state --&gt; State3\n\n    state join_state &lt;&lt;join&gt;&gt;\n    State2 --&gt; join_state\n    State3 --&gt; join_state\n    join_state --&gt; State4\n    State4 --&gt; [*]\n```\n</code></pre>"},{"location":"cheatsheet/diagrams/#class-diagram","title":"Class diagram","text":"<p>Class diagram</p> AspectCode <pre><code>classDiagram\nPerson &lt;|-- Student\nPerson &lt;|-- Professor\nPerson : +String name\nPerson : +String phoneNumber\nPerson : +String emailAddress\nPerson: +purchaseParkingPass()\nAddress \"1\" &lt;-- \"0..1\" Person:lives at\nclass Student{\n    +int studentNumber\n    +int averageMark\n    +isEligibleToEnrol()\n    +getSeminarsTaken()\n}\nclass Professor{\n    +int salary\n}\nclass Address{\n    +String street\n    +String city\n    +String state\n    +int postalCode\n    +String country\n    -validate()\n    +outputAsLabel()  \n}</code></pre> <pre><code>``` mermaid\nclassDiagram\nPerson &lt;|-- Student\nPerson &lt;|-- Professor\nPerson : +String name\nPerson : +String phoneNumber\nPerson : +String emailAddress\nPerson: +purchaseParkingPass()\nAddress \"1\" &lt;-- \"0..1\" Person:lives at\nclass Student{\n    +int studentNumber\n    +int averageMark\n    +isEligibleToEnrol()\n    +getSeminarsTaken()\n}\nclass Professor{\n    +int salary\n}\nclass Address{\n    +String street\n    +String city\n    +String state\n    +int postalCode\n    +String country\n    -validate()\n    +outputAsLabel()  \n}\n```\n</code></pre>"},{"location":"cheatsheet/diagrams/#entity-relationship-diagram","title":"Entity Relationship Diagram","text":"<p>Entity Relationship Diagram</p> AspectCode <pre><code>    erDiagram\n        CUSTOMER ||--o{ ORDER : places\n        ORDER ||--|{ LINE-ITEM : contains\n        CUSTOMER }|..|{ DELIVERY-ADDRESS : uses</code></pre> <pre><code>```mermaid\nerDiagram\n    CUSTOMER ||--o{ ORDER : places\n    ORDER ||--|{ LINE-ITEM : contains\n    CUSTOMER }|..|{ DELIVERY-ADDRESS : uses\n```\n</code></pre>"},{"location":"cheatsheet/generic_formatting/","title":"Generic formatting","text":""},{"location":"cheatsheet/generic_formatting/#titles","title":"TitlesSmall Title","text":"<p>Titles</p> AspectMarkdownHTML <p>Big Title Medium Title Small Sub Title Very Small Title Very Small Sub Title <pre><code># Big Title\n## Medium Title\n### Small Title\n#### Small Sub Title\n##### Very Small Title\n###### Very Small Sub Title\n</code></pre> <pre><code>&lt;h1&gt;Big Title&lt;/h1&gt;\n    &lt;h2&gt;Medium Title&lt;/h2&gt;\n        &lt;h3&gt;Small Title&lt;/h3&gt;\n            &lt;h4&gt;Small Sub Title&lt;/h4&gt;\n                &lt;h5&gt;Very Small Title&lt;/h3&gt;\n                    &lt;h6&gt;Very Small Sub Title&lt;/h4&gt;\n</code></pre>"},{"location":"cheatsheet/generic_formatting/#text-formatting","title":"Text formatting","text":"<p>Text formatting</p> AspectMarkdown <p>This is some bold text This is some italic text This is some bold italic text This is some <code>in-line code</code> This is some underlined text This is some crossed out text This is some highlighted text</p> <pre><code>This is some **bold text**  \nThis is some *italic text*  \nThis is some ***bold italic text***  \nThis is some `inline code`  \nThis is some ^^underlined text^^  \nThis is some ~~crossed out text~~  \nThis is some ==highlighted text==\n</code></pre>"},{"location":"cheatsheet/generic_formatting/#horizontal-separator","title":"Horizontal separator","text":"<p>Horizontal separator</p> AspectMarkdown <p>Some text</p> <p>Some text under the separator    </p> <pre><code>***\n---\n___\n</code></pre>"},{"location":"cheatsheet/generic_formatting/#quote-blocs","title":"Quote blocs","text":"<p>Quote blocs</p> AspectMarkdown <p>Never laugh at live dragons.  J.R.R. Tolkien </p> <pre><code>&gt; Never laugh at live dragons. \n&gt; J.R.R. Tolkien \n</code></pre>"},{"location":"cheatsheet/generic_formatting/#definition-list","title":"Definition list","text":"<p>Definition list</p> AspectMarkdown Random <ol> <li>Having no specific pattern, purpose, or objective: synonym: chance.</li> </ol> <ol> <li>Of or relating to a type of circumstance or event that is described by a probability distribution. </li> </ol> <pre><code>Random\n: 1. Having no specific pattern, purpose, or objective: synonym: chance.\n: 2. Of or relating to a type of circumstance or event that is described by a probability distribution. \n</code></pre>"},{"location":"cheatsheet/generic_formatting/#code-formatting","title":"Code formatting","text":""},{"location":"cheatsheet/generic_formatting/#inline-code","title":"Inline code","text":"<p>Inline code</p> AspectMarkdown <p>This is some <code>inline code</code> </p> <pre><code>This is some `inline code`  \n</code></pre>"},{"location":"cheatsheet/generic_formatting/#code-bloc","title":"Code bloc","text":"<p>Code bloc</p> AspectMarkdown randomJavaClass.java<pre><code>public class HelloWorld {\n  // This is a comment\n  public static void main(String[] arg){\n    // This is another one\n    System.out.println(\"Hello world\");\n  }\n} \n</code></pre> <pre><code>```java hl_lines=\"1-2 5 7\" linenums=\"1\" title=\"randomJavaClass.java\"\npublic class HelloWorld {\n  // This is a comment\n  public static void main(String[] arg){\n    // This is another one\n    System.out.println(\"Hello world\");\n  }\n} \n```\n</code></pre>"},{"location":"cheatsheet/generic_formatting/#lists","title":"Lists","text":""},{"location":"cheatsheet/generic_formatting/#ordered-list","title":"Ordered list","text":"<p>Ordered list</p> AspectMarkdownHTML <ol> <li>First</li> <li>second</li> <li>Then (numbers don't matter)</li> <li>Finally, a last one</li> </ol> <pre><code>1. First\n2. Second\n1. Then (numbers don't matter)\n4. Finally, a last one\n&lt;/a&gt; #Stopping the list\n</code></pre> <pre><code>&lt;ol&gt;\n  &lt;li&gt;First&lt;/li&gt;\n  &lt;li&gt;second&lt;/li&gt;\n  &lt;li&gt;Then (numbers don't matter)&lt;/li&gt;\n  &lt;li&gt;Finally, a last one&lt;/li&gt;\n&lt;/ol&gt;\n</code></pre>"},{"location":"cheatsheet/generic_formatting/#unordered-list","title":"Unordered list","text":"<p>Unordered list</p> AspectMarkdownHTML <ul> <li>First</li> <li>Second<ul> <li>Third</li> </ul> </li> </ul> <pre><code>- First\n- Second\n    + Third\n</code></pre> <pre><code>&lt;ul&gt;\n    &lt;li&gt;First&lt;/li&gt;\n    &lt;li&gt;Second&lt;/li&gt;\n    &lt;ul&gt;\n        &lt;li&gt;Third&lt;/li&gt;\n    &lt;/ul&gt;\n&lt;/ul&gt;\n</code></pre>"},{"location":"cheatsheet/generic_formatting/#tasklist","title":"Tasklist","text":"<p>Tasklist</p> AspectCode <ul> <li> Lorem ipsum dolor sit amet, consectetur adipiscing elit</li> <li> Vestibulum convallis sit amet nisi a tincidunt<ul> <li> In hac habitasse platea dictumst</li> <li> In scelerisque nibh non dolor mollis congue sed et metus</li> <li> Praesent sed risus massa</li> </ul> </li> <li> Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque</li> </ul> <pre><code>* [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit\n* [ ] Vestibulum convallis sit amet nisi a tincidunt\n    * [x] In hac habitasse platea dictumst\n    * [x] In scelerisque nibh non dolor mollis congue sed et metus\n    * [ ] Praesent sed risus massa\n* [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque\n</code></pre>"},{"location":"cheatsheet/generic_formatting/#emojis","title":"Emojis","text":"<p>Extensive emoji list</p> Emoji Aspect <code>:alien:</code> <code>:yum:</code> <code>:confused:</code> <code>:smirk:</code> <code>:kiss:</code> <code>:frog:</code> <code>:fr:</code> <code>:gb:</code> <code>:tongue:</code> <code>:computer:</code>"},{"location":"cheatsheet/generic_formatting/#footnotes","title":"Footnotes","text":"<p>Note</p> AspectCode <p>This is the first way<sup>1</sup> to define a footnote. This is some boring text. This is another way<sup>2</sup> to define a footnote. Another boring text</p> <pre><code>This is the first way[^1] to define a footnote.  \nThis is some boring text.\nThis is another way[^t] to define a footnote.  \nAnother boring text\n\n[^1]: Using numbers\n[^t]: It's also possible to use characters\n</code></pre> <ol> <li> <p>Using numbers\u00a0\u21a9</p> </li> <li> <p>It's also possible to use characters\u00a0\u21a9</p> </li> </ol>"},{"location":"cheatsheet/links_and_images/","title":"Links and images","text":""},{"location":"cheatsheet/links_and_images/#links-and-references","title":"Links and references","text":""},{"location":"cheatsheet/links_and_images/#external-references","title":"External references","text":"<p>External references</p> AspectMarkdown <p>inline link Referencing with a number Using a direct link.  </p> <pre><code>[inline link](https://example.com/)  \n[Referencing with a number][1]  \nUsing a [direct link].  \n[direct link]: https://example.com/  \n[1]: https://example.com/  \n</code></pre>"},{"location":"cheatsheet/links_and_images/#internal-links","title":"Internal links","text":"<p>Internal links</p> AspectMarkdown <p>Reference to a file Reference to a title</p> <pre><code>[Reference to a file](../cheatsheet/links_and_images.md/)  \n[Reference to a title](#links-and-references)\n</code></pre>"},{"location":"cheatsheet/links_and_images/#images","title":"Images","text":"<p>Images</p> AspectMarkdown <p>Online image: </p> <p>Reference style: </p> <pre><code>Online image:\n![alt text](https://dummyimage.com/200x100/eee/aaa \"Logo Title Text 1\")\n\nReference style: \n![alt text][logo]\n\n[logo]: https://dummyimage.com/200x100/eee/aaa \"Logo Title Text 2\"\n</code></pre> <p>Image alignment</p> <p>It possible to align an image right or left using this:</p> AspectMarkdown <p> Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <pre><code>![Placeholder](https://dummyimage.com/200x100/eee/aaa){: align=right }\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n</code></pre>"},{"location":"cheatsheet/links_and_images/#youtube-video","title":"Youtube video","text":"<p>Videos YouTube</p> AspectMarkdown <p></p> <pre><code>[![IMAGE ALT TEXT HERE](http://img.youtube.com/vi/dQw4w9WgXcQ/0.jpg)](https://www.youtube.com/watch?v=dQw4w9WgXcQ)\n</code></pre>"},{"location":"cheatsheet/maths/","title":"Maths","text":""},{"location":"cheatsheet/maths/#latex","title":"LaTex","text":"<p>LaTex</p> <p>To use LaTex, simply surround the formula with the '$' symbol.</p> Operation LaTex Aspect Sign \\(\\times\\) \\times \\(\\times\\) Power a^{b} \\(a^{b}\\) Subscript a_{b} \\(a_{b}\\) Root \\sqrt[n]{x} \\(\\sqrt[n]{x}\\) Fraction \\frac{a}{c} \\(\\frac{a}{c}\\) Sum \\sum_{i=0}^n \\(\\sum_{i=0}^n\\) Product \\prod_{i=0}^n \\(\\prod_{i=0}^n\\) Fraction \\frac{a}{c} \\(\\frac{a}{c}\\) Integral \\int_a^b \\(\\int_a^b\\) Greeks characters \\alpha \\(\\alpha\\) Trigonometric functions \\sin \\(\\sin\\) Exponential \\exp(x) \\(\\exp(x)\\) Infinity \\infty \\(\\infty\\) Vector \\vec{a} \\(\\vec{a}\\)"},{"location":"cheatsheet/maths/#subsuperscript","title":"Sub/Superscript","text":"<p>Sub/Superscript</p> AspectMarkdown <p>H<sub>2</sub>O X<sup>2</sup> </p> <pre><code>H~2~O  \nX^2^\n</code></pre>"},{"location":"cheatsheet/superfences_and_tabs/","title":"Superfences and tabs","text":""},{"location":"cheatsheet/superfences_and_tabs/#superfences","title":"SuperFences","text":"<p>SuperFences are just Tabs inside an alert bloc</p> <p>SuperFences</p> AspectMarkdown <p>SuperFences</p> BashCC++C# <pre><code>#!/bin/bash\necho \"Hello world!\"\n</code></pre> <pre><code>#include &lt;stdio.h&gt;\nint main(void) {\n  printf(\"Hello world!\\n\");\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\nint main() {\n  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre> <pre><code>using System;\nclass Program {\n  static void Main(string[] args) {\n    Console.WriteLine(\"Hello world!\");\n  }\n}\n</code></pre> <pre><code>!!! example \"SuperFences\"\n            === \"Bash\"\n                ```bash\n                #!/bin/bash\n                echo \"Hello world!\"\n                ```\n            === \"C\"\n                ```c\n                #include &lt;stdio.h&gt;\n                int main(void) {\n                  printf(\"Hello world!\\n\");\n                }\n                ```\n            === \"C++\"\n                ```cpp\n                #include &lt;iostream&gt;\n                int main() {\n                  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n                  return 0;\n                }\n                ```\n            === \"C#\"\n                ```cs\n                using System;\n                class Program {\n                  static void Main(string[] args) {\n                    Console.WriteLine(\"Hello world!\");\n                  }\n                }\n                ```\n</code></pre>"},{"location":"cheatsheet/superfences_and_tabs/#tabs","title":"Tabs","text":"AspectCode BashCC++C# <pre><code>#!/bin/bash\necho \"Hello world!\"\n</code></pre> <pre><code>#include &lt;stdio.h&gt;\nint main(void) {\n  printf(\"Hello world!\\n\");\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\nint main() {\n  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre> <pre><code>using System;\nclass Program {\n  static void Main(string[] args) {\n    Console.WriteLine(\"Hello world!\");\n  }\n}\n</code></pre> <pre><code>    === \"Bash\"\n        ```bash\n        #!/bin/bash\n        echo \"Hello world!\"\n        ```\n    === \"C\"\n        ```c\n        #include &lt;stdio.h&gt;\n        int main(void) {\n          printf(\"Hello world!\\n\");\n        }\n        ```\n    === \"C++\"\n        ```cpp\n        #include &lt;iostream&gt;\n        int main() {\n          std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n          return 0;\n        }\n        ```\n    === \"C#\"\n        ```cs\n        using System;\n        class Program {\n          static void Main(string[] args) {\n            Console.WriteLine(\"Hello world!\");\n          }\n        }\n        ```\n</code></pre>"},{"location":"cheatsheet/superfences_and_tabs/#alertspoiler-blocs","title":"Alert/Spoiler blocs","text":"<p>Alert/Spoiler blocs</p> AspectMarkdown Spoiler <p>This is a spoiler</p> <p>note ou seealso</p> <p>blablabla</p> <p>tip ou hint ou important</p> <p>info ou todo</p> <p>question ou help ou faq</p> <p>summary</p> <p>warning ou caution ou attention</p> <p>failure ou fail ou missing</p> <p>check ou done</p> <p>danger ou error</p> <p>bug</p> <p>quote</p> <p>example</p> <pre><code>??? warning \"Spoiler\"\n    This is a spoiler\n\n!!! note \"note ou seealso\"\n    blablabla\n\n!!! tip \"tip ou hint ou important\"\n\n!!! info \"info ou todo\"\n\n!!! help \"question ou help ou faq\"\n\n!!! summary \"summary\"\n\n!!! warning \"warning ou caution ou attention\"\n\n!!! failure \"failure ou fail ou missing\"\n\n!!! done \"check ou done\"\n\n!!! danger \"danger ou error\"\n\n!!! bug \"bug\"\n\n!!! quote \"quote\"\n\n!!! example \"example\"\n</code></pre>"},{"location":"cheatsheet/tables/","title":"Tables","text":""},{"location":"cheatsheet/tables/#tables","title":"Tables","text":"<p>Usefull tool </p> <p>Table</p> LeftCenterRight AspectMarkdown Firstname Lastname Age Jill Smith 50 Eve Jackson 94 <pre><code>| Firstname | Lastname | Age |\n|:----------|:---------|:----|\n| Jill      | Smith    | 50  |\n| Eve       | Jackson  | 94  |\n</code></pre> AspectMarkdown Firstname Lastname Age Jill Smith 50 Eve Jackson 94 <pre><code>| Firstname | Lastname | Age |\n|:---------:|:--------:|:---:|\n| Jill      | Smith    | 50  |\n| Eve       | Jackson  | 94  |\n</code></pre> AspectMarkdown Firstname Lastname Age Jill Smith 50 Eve Jackson 94 <pre><code>| Firstname | Lastname | Age |\n|----------:|---------:|----:|\n| Jill      | Smith    | 50  |\n| Eve       | Jackson  | 94  |\n</code></pre>"},{"location":"scripts/","title":"Index","text":"<p>To automate a maximum my homelab, scripting is key. For this it's great to develop scripts, but it's even better if those scripts have complete documentation explaining what they're doing and how to set this up.</p> <p>Come on let's script again !!</p>"},{"location":"scripts/pwm_fan_control/","title":"PWM fan control","text":""},{"location":"scripts/pwm_fan_control/#description","title":"Description","text":"<p>This script is dedicated to control a PWM fan on my Raspberry PI 4B 8 Go. To use correctly this script, please install the fan following the information bellow :</p> <p>Be sure to plug the cable accordingly !</p> <p></p>"},{"location":"scripts/pwm_fan_control/#script-overview","title":"Script overview","text":"pwm_fan_control.py<pre><code>import RPi.GPIO as GPIO # type: ignore\nimport time\nimport subprocess\n\n# Configuration constants\nGPIO_PIN = 14\nTEMP_THRESHOLD = 50.0\nPWM_FREQUENCY = 100\n\n# GPIO pin setup\nGPIO.setmode(GPIO.BCM)\n# Set to false, other processes occupying the pin will be ignored\nGPIO.setwarnings(False)\nGPIO.setup(GPIO_PIN, GPIO.OUT)\npwm = GPIO.PWM(GPIO_PIN,PWM_FREQUENCY)\n\n# Initialize PWM\ndc = 0\npwm.start(dc)\n\ndef get_cpu_temperature():\n    \"\"\"Retrieves the CPU temperature using vcgencmd.\"\"\"\n    try:\n        temp_str = subprocess.getoutput(\"vcgencmd measure_temp | sed 's/[^0-9.]//g'\")\n        return float(temp_str)\n    except Exception as e:\n        print(f\"Error retrieving temperature: {e}\")\n        return 0.0\n\ntry:\n    while True:\n        temp = get_cpu_temperature()\n        time.sleep(1)\n\n        # Adjust duty cycle based on temperature\n        if temp &gt;= TEMP_THRESHOLD:\n            new_dc = 100\n        else:\n            new_dc = 0\n\n        # Update duty cycle if necessary\n        if new_dc != dc:\n            dc = new_dc\n            pwm.ChangeDutyCycle(dc)\n\nexcept KeyboardInterrupt:\n    print(\"Stopping the script.\")\nfinally:\n    pwm.stop()\n    GPIO.cleanup()\n</code></pre>"},{"location":"scripts/pwm_fan_control/#setup","title":"Setup","text":"<ol> <li>Ensuring the GPIO lib is isntalled : <code>pip freeze | grep RPi.GPIO</code></li> <li>Creating a systemd service file : <code>sudo nano /etc/systemd/system/pwm_fan_control.service</code></li> <li>Add : pwm_fan_control.service<pre><code>[Unit]\nDescription=My Python Script Service\nAfter=network.target\n\n[Service]\nUser=palpi\nExecStart=/usr/bin/python /home/palpi/palpi/scripts/pwm_fan_control.py\nWorkingDirectory=/home/palpi/palpi/scripts\nStandardOutput=null\nStandardError=null\n\n[Install]\nWantedBy=multi-user.target\n</code></pre></li> <li>Reloading systemctl : <code>sudo systemctl daemon-reload</code></li> <li>Enabling our service : <code>sudo systemctl enable pwm_fan_control.service</code></li> <li>Starting our service : <code>sudo systemctl start pwm_fan_control.service</code></li> <li>Checking our service : <code>sudo systemctl status pwm_fan_control.service</code></li> </ol> <p>How to test the script</p> <ul> <li>Stress the CPU to increase the temp : <code>fulload() { dd if=/dev/zero of=/dev/null | dd if=/dev/zero of=/dev/null | dd if=/dev/zero of=/dev/null  | dd if=/dev/zero of=/dev/null &amp; }; fulload; read; killall dd</code>   The more <code>| dd if=/dev/zero of=/dev/null</code> the higher it will reach</li> <li>You can check the temp with <code>vcgencmd measure_temp|sed 's/[^0-9.]//g'</code></li> </ul>"},{"location":"blog/archive/2026/","title":"2026","text":""},{"location":"blog/archive/2026/#2026","title":"2026","text":""},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/archive/2025/#2025","title":"2025","text":""}]}